---
title: "CodeBook"
author: "Kirsten Meeker"
date: "May 16, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Abstract: 
Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.

## Tidy Data:
tidy_data.csv  
180 observations of 81 variables

#Attributes:
subject (integer): identifier of the subject who carried out the experiment
activity (factor with 6 levels): WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING

Means of:
tBodyAcc-mean() (g): estimated body acceleration x,y,z 
tGravityAcc-mean() (g): acceleration due to gravity x,y,z
tBodyAccJerk-mean() (g/s): acceleration jerk x,y,z
tBodyGyro-mean() (radians/second): angular velocity x,y,z
tBodyGyroJerk-mean() (radians/second/second): angular velocity jerk x,y,z

tBodyAccMag-mean() (g): magnitude of body acceleration
tGravityAccMag-mean(g): magnitude of gravity
tBodyAccJerkMag-mean(g/s): magnitude of acceleration jerk
tBodyGyroMag-mean(radians/second): magnitude of angular velocity
tBodyGyroJerkMag-mean(radians/second/second): magnitude of angular velocity jerk

frequency domain signals computed from FFT of same measures as means:
fBodyAcc-mean()
fBodyAcc-meanFreq()
fBodyAccJerk-mean()
fBodyAccJerk-meanFreq()
fBodyGyro-mean()
fBodyGyro-meanFreq()

fBodyAccMag-mean()
fBodyAccMag-meanFreq()
fBodyBodyAccJerkMag-meanFreq()
fBodyBodyGyroMag-mean()
fBodyBodyGyroMag-meanFreq()
fBodyBodyGyroJerkMag-mean()
fBodyBodyGyroJerkMag-meanFreq()

standard deviations of same measures as means:
tBodyAcc-std()
tGravityAcc-std()
tBodyAccJerk-std()
tBodyGyro-std()
tBodyGyroJerk-std()

tBodyAccMag-std()
tGravityAccMag-std() 
tBodyAccJerkMag-std()
fBodyGyro-std()

fBodyAccMag-std()
fBodyBodyAccJerkMag-std()
fBodyBodyGyroMag-std()
fBodyBodyGyroJerkMag-std()

## Study Design

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.


## Raw Data
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. 

#Source:

Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)
1 - Smartlab - Non-Linear Complex Systems Laboratory
DITEN - Università degli Studi di Genova, Genoa (I-16145), Italy. 
2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living
Universitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), Spain
activityrecognition '@' smartlab.ws

#Citation Request:

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.
